{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb02514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi\n",
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "aplay: main:831: audio open error: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masiha :  m nhi btaunga\n",
      "You: hi\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "aplay: main:831: audio open error: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masiha :  Not much, just taking it easy. How about you?\n",
      "You: hi'\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "aplay: main:831: audio open error: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masiha :  Hi!\n",
      "You:  bye\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Masiha :  Okay, bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "aplay: main:831: audio open error: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pyttsx3\n",
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Initialize the TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set the voice properties (optional)\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)  # Change index to select a different voice\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_csv('cleaned_dataset.csv')\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tag'])\n",
    "\n",
    "input_shape=16\n",
    "vocabulary = 445\n",
    "output_length = 6\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['input'])\n",
    "model=keras.models.load_model('modl3-0.h5')\n",
    "while True:\n",
    "    texts_p = []\n",
    "    prediction_input1 = input('You: ')\n",
    "    \n",
    "#removing punctuation and converting to lowercase    \n",
    "    prediction_input = [letters.lower() for letters in prediction_input1 if letters not in string.punctuation]\n",
    "    prediction_input =''.join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    prediction_input = prediction_input.strip().split(' ')\n",
    "    integers = []\n",
    "    floats = []\n",
    "\n",
    "    for n, element in enumerate(prediction_input):\n",
    "        try:\n",
    "            integer_value = int(element)\n",
    "            integers.append((integer_value, n))\n",
    "        except ValueError:\n",
    "            try:\n",
    "                float_value = float(element)\n",
    "                floats.append((float_value, n))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    if integers:\n",
    "        for value, index in integers:\n",
    "            curr=value\n",
    "            idx=index\n",
    "            convert_from=prediction_input[idx+1].upper()\n",
    "            convert_to=prediction_input[idx+3].upper()\n",
    "        import requests\n",
    "\n",
    "        api_key = '97WwQWGRmUjka1Qk2BZjZyGKRRN2WCE5'\n",
    "        endpoint = f'https://api.apilayer.com/currency_data/convert?to={convert_to}&from={convert_from}&amount={curr}'\n",
    "\n",
    "        headers = {\n",
    "            'apikey': api_key\n",
    "            }\n",
    "\n",
    "        respon = requests.get(endpoint, headers=headers)\n",
    "        s = respon.json()\n",
    "        covted=s['result']\n",
    "        \n",
    "        prediction_input = [letters.lower() for letters in prediction_input1 if letters not in string.punctuation]\n",
    "        prediction_input =''.join(prediction_input)\n",
    "        texts_p.append(prediction_input)\n",
    "\n",
    "        #tokenizing and padding\n",
    "        prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "        prediction_input = np.array(prediction_input).reshape(-1)\n",
    "        prediction_input = pad_sequences([prediction_input], input_shape)\n",
    "        #getting output from model\n",
    "\n",
    "\n",
    "        output = model.predict(prediction_input)\n",
    "        output = output.argmax()\n",
    "        #finding the right tag and predicting\n",
    "        response_tag = le.inverse_transform([output])[0]\n",
    "        print(response_tag)\n",
    "        # print(data[data['tag']==response_tag.strip()]['input'])\n",
    "        print(\"Masiha : \",random.choice(data[data['tag']==response_tag.strip()]['responses'].reset_index(drop=True)),covted,convert_to)\n",
    "    elif floats:\n",
    "        for value, index in floats:\n",
    "            curr=value\n",
    "            idx=index\n",
    "            convert_from=prediction_input[idx+1]\n",
    "            convert_to=prediction_input[idx+3]\n",
    "        import requests\n",
    "\n",
    "        api_key = '97WwQWGRmUjka1Qk2BZjZyGKRRN2WCE5'\n",
    "        endpoint = f'https://api.apilayer.com/currency_data/convert?to={convert_to}&from={convert_from}&amount={curr}'\n",
    "\n",
    "        headers = {\n",
    "            'apikey': api_key\n",
    "            }\n",
    "\n",
    "        respon = requests.get(endpoint, headers=headers)\n",
    "        s = respon.json()\n",
    "        covted=s['result']\n",
    "        prediction_input = [letters.lower() for letters in prediction_input1 if letters not in string.punctuation]\n",
    "        prediction_input =''.join(prediction_input)\n",
    "        texts_p.append(prediction_input)\n",
    "\n",
    "        #tokenizing and padding\n",
    "        prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "        prediction_input = np.array(prediction_input).reshape(-1)\n",
    "        prediction_input = pad_sequences([prediction_input], input_shape)\n",
    "        #getting output from model\n",
    "\n",
    "\n",
    "        output = model.predict(prediction_input)\n",
    "        output = output.argmax()\n",
    "        #finding the right tag and predicting\n",
    "        response_tag = le.inverse_transform([output])[0]\n",
    "        print(response_tag)\n",
    "        # print(data[data['tag']==response_tag.strip()]['input'])\n",
    "        print(\"Masiha : \",random.choice(data[data['tag']==response_tag.strip()]['responses'].reset_index(drop=True)),covted,convert_to)\n",
    "    else:\n",
    "            prediction_input = [letters.lower() for letters in prediction_input1 if letters not in string.punctuation]\n",
    "            prediction_input =''.join(prediction_input)\n",
    "            texts_p.append(prediction_input)\n",
    "\n",
    "        #tokenizing and padding\n",
    "            prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "            prediction_input = np.array(prediction_input).reshape(-1)\n",
    "            prediction_input = pad_sequences([prediction_input], input_shape)\n",
    "        #getting output from model\n",
    "\n",
    "\n",
    "            output = model.predict(prediction_input)\n",
    "            output = output.argmax()\n",
    "        #finding the right tag and predicting\n",
    "            response_tag = le.inverse_transform([output])[0]\n",
    "            #print(response_tag)\n",
    "        # print(data[data['tag']==response_tag.strip()]['input'])\n",
    "            x=random.choice(data[data['tag']==response_tag.strip()]['responses'].reset_index(drop=True))\n",
    "        # Convert text to speech\n",
    "            engine.say(x)\n",
    "            engine.runAndWait()\n",
    "            print(\"Masiha : \",random.choice(data[data['tag']==response_tag.strip()]['responses'].reset_index(drop=True)))\n",
    "            if response_tag==\"goodbye\":\n",
    "                break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea96814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set the voice properties (optional)\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)  # Change index to select a different voice\n",
    "\n",
    "# Get input from the user\n",
    "text = input(\"Enter the text you want to convert to speech: \")\n",
    "\n",
    "# Convert text to speech\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
